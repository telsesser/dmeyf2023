
4/9/23

## Z401

Feature engineering:
2_ importancia de variables

sumar cantidad te tarjetas visa con las master y el resto
relacion entre prestado/saldo en cuenta. 
combinar comisiones
Sacar numero de cliente 

3_ datos nulos:
rpart acepta manejo de datos nulos
imputar nomás si estoy seguro que nulo=0
	imputar por valores arbitriarios es dificil que funcione

4_ Correlaciones:
en otros algoritmos: hay que evitar las correlaciones por que afecta los calculos matriciales
En los arboles el mismo algoritmo suele eliminarlas

5_ Outliers
No son un problema los outliers (para árboles), no gastar tiempo en esto

6_ Data driftting
Cuando el modelo deja de funcionar por que cambia la relevancia o peso de los datos.
La inflación por ejemplo, pero en este caso al estar de un mes a otro no afecta. 
El aguinaldo, bonos, etc. pueden afectar.
Por ejemplo antes eran importantes las cantidad de cheques, después el uso del homebanking y ahora las app. 
El módelo se tiene que ir actualizando.

conseptual driftting serían por ejemplo los fraudes que no se podrían modeloar porque cuando se detecta uno 
ya cambian la metodologí y el módelo no me sirve para identificar los nuevos fraudes.

TODO: probar decilado de 10, 100. O sea asignar el 10% más bajos al primer decil, el siguiente 10% al segundo decil y así.

Para hacer:
Tomar modelo de la carpeta rpart
Buscar variables que arreglen el datadrifting en algo (al hacerlo sacar variable original)
Hacer featuring engineering (más que nada combinar variables)
dejar el rpart corriendo mientras pienso el fueature engineering porque tarda mucho en ejecutar 
(dijo 1 día)
filtrar la cantidad de 1 en la salida, el punto de corte, para ir probando diferentes en el kaggle. 
para hacer esto quedarme con por ejemplo los primeros 10000 que más probabilidades tengan de ser +1
buscar la meseta en el public, en que valores empieza a bajar mucho el score. 


11/9 
Sobre canaritos
A medida que más profundo es el arbol, en ramás más bajas evalua con menos datos entonces tengo más posibilidades
de tener "suerte" de que una variable aleatoria parezca que tiene una relación con el target.

TODO: Cosas que funcionaron tp2
* Analizar como meter el baja+2, baja+3, etc., en vez de solo dejar el continua
* ver que meses elegir. el que gano el año pasado eligió un par de meses puntuales 


Ver: drifting/densidades_fgeneral
ver: CatastroprheAnalysis. ver si eliminar columna o ese mes, o tratar de imputar esa variable. 

# 
25/19/23
TODO: Para probar en el tp:
* delta de una variable
* Media movil (ver si en el mes está debajo o encima de la media)
* variación con respecto a los meses
* minimo y maximo historicos de una variable
* Tendencia: ver ejemplo en zulip: https://dmeyf2023.zulip.rebelare.com/#narrow/stream/401-Code/topic/.5Btip.5D.20features.20historicos.20usando.20SQL
	con regr_slope(y, x)
	Esto es muy sensible a outlierts
	* Otra puede ser mes_actual/promedio_ultimos_6_meses
	* prom_ult_3_meses/prom_ult_6_meses

* Ver que en el medio está la pandemia

02/10/23
TODO:
* Meter mano en la búsqueda bayeseana, que no es necesario todo lo que recorre. Para que no tarde tanto.
* Para la optimización bayeseana hacer un undersampling porque sino va a tardar una banda. 
* podría agregar:
	+ Saldo de la tarjeta / limite
	+ Bins con el saldo o plata en cuenta para separar por clase social
	+ Ver la variabilidad de la cuenta sueldo.
	
- Para el video de Miranda:
	+ Hacer feature engineering para reducir el número de variables para poder explicar. 
	+ Ver el power point(!)
	+ Contar historias cortas sobre los cluster. Que características tienen y que termina siendo 
		que ese grupo se termine yendo. 
	+ El máximo es 5 minutos, puede ser menos. 
	+ El script que habla la presentacion en la hoja 5 no es un código sino un speach.
	+ La presentacion tiene que ser minima. Hasta si se hace sin presentacion mejor.
		El criterio es dejar solo lo que es muy dificil de explicar con palabras o 
		en una presentación sería muy esclarecedor.
	
	+ Dar confianza
	+ No querer mostrar todo lo que si sino convencer a la otra persona
	+ Leer la historia de Miranda 
	+ pensar que gastaría un gran presupuesto con esto 
	Se puede decir "tenemos este segmento de gente qeu se caracteriza por x
	y cuando tienen x conducta ..."

Clase 9/10/23
En los modelos de boosting son muy robustos a variables correlaciondas pero 
cuando son muchas si afecta. 
TODO: Probar dejando las variables que les hice feature engineering
	  Probar calculando la pendiente de los bins.
	  Agregar el mes+3
	  TODO: Ver lo de CatastroprheAnalysis

Clase 23/10/23: 	
TODO: CatastroprheAnalysis ver como hacer la interpolación cuando ese cliente se fue al més siguiente..


TODO: Hacer varios modelos y juntarlos los resultados de cada uno para cada N°cliente+foto_mes
Luego aplicar votación(por mayoria o cuantos correctos para mandar, por ejemplo con 1, 2 o 3 que esten
de acuerdo ya pongo como ok), promedio, un metamodelo que tome esta decisión en base a los resultados
de los otros modelos. No ir por esta ultima de una porque toma mucho tiempo, con el promedio va bien. 
Hacer diferentes modelos cambiando: Semillas, hiperparámetros, probar otros algoritmos, etc. 


